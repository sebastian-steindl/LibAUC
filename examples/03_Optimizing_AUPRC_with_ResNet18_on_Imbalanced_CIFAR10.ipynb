{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[LibAUC]Training_AUPRCLoss_on_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwnB4qhzRo-U"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw6cuynswP_w",
        "outputId": "f591b9ee-ac41-4a28-dea2-921101f06831"
      },
      "source": [
        "!pip install libauc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./libauc-1.1.1.tar.gz\n",
            "Building wheels for collected packages: libauc\n",
            "  Building wheel for libauc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libauc: filename=libauc-1.1.1-cp37-none-any.whl size=33754 sha256=0fc287ca59570b518b5db34e7fbcd9d61212d42291ecd0622957f88062048585\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/2a/27/f4148c7f23ea7862a66a50af8b8753116d83c669f95916e898\n",
            "Successfully built libauc\n",
            "Installing collected packages: libauc\n",
            "  Found existing installation: libauc 1.1.1\n",
            "    Uninstalling libauc-1.1.1:\n",
            "      Successfully uninstalled libauc-1.1.1\n",
            "Successfully installed libauc-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qWCXSTRvIK"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvcM8kpziqv4"
      },
      "source": [
        "from libauc.losses import SOAPLoss\n",
        "from libauc.optimizers import SGD\n",
        "from libauc.models import ResNet18\n",
        "from libauc.datasets import CIFAR10\n",
        "from libauc.datasets import ImbalanceGenerator, ImbalanceSampler \n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N286JDgSIy4"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GXbHx1SLfy"
      },
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE-hFHH1SNuu"
      },
      "source": [
        "# **Image Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg85RS7_woYS"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                                \n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.RandomCrop((crop_size, crop_size), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.Resize((image_size, image_size)),\n",
        "                              \n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return idx, image, target\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEVuk9mWSWgE"
      },
      "source": [
        "# **Paramaters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Wn9WTGSdmD"
      },
      "source": [
        "# paramaters\n",
        "imratio = 0.02\n",
        "SEED = 123\n",
        "BATCH_SIZE = 64\n",
        "lr =  0.6\n",
        "weight_decay = 2e-4\n",
        "margin = 0.5\n",
        "gamma = 0.99\n",
        "posNum = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5TQ6QMSZ_Z"
      },
      "source": [
        "# **Loading datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsp3lUzXShgI",
        "outputId": "f8418860-70ef-4634-de32-297d0418ccb8"
      },
      "source": [
        "# dataloader \n",
        "(train_data, train_label), (test_data, test_label) = CIFAR10()\n",
        "(train_images, train_labels) = ImbalanceGenerator(train_data, train_label, imratio=imratio, shuffle=True, random_seed=SEED)\n",
        "(test_images, test_labels) = ImbalanceGenerator(test_data, test_label, is_balanced=True,  random_seed=SEED)\n",
        "\n",
        "train_dataset = ImageDataset(train_images, train_labels)\n",
        "test_dataset = ImageDataset(test_images, test_labels, mode='test')\n",
        "testloader = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE, shuffle=False, num_workers=1,  pin_memory=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_SAMPLES: [25510], POS:NEG: [510 : 25000], POS_RATIO: 0.0200\n",
            "NUM_SAMPLES: [10000], POS:NEG: [5000 : 5000], POS_RATIO: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyXxZxRvSjOO"
      },
      "source": [
        "# **Creating models & AUC Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC4ihPQASmSY",
        "outputId": "b916b922-d503-43d1-8dfa-9d6ed9844e23"
      },
      "source": [
        "set_all_seeds(456)\n",
        "model = ResNet18(pretrained=False, last_activation=None)  # last_activation=False: don't include sigmoid function in the last layer\n",
        "model = model.cuda()\n",
        "\n",
        "Loss = SOAPLoss(margin=margin, gamma=gamma, data_len=train_labels.shape[0])\n",
        "optimizer = SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.modules.activation.ReLU'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0nJp7NS4Ne"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64xZXszhwqmK",
        "outputId": "c3afbce2-1fd4-451b-bb32-eb619e75af3f"
      },
      "source": [
        "# training \n",
        "model.train()\n",
        "losses = []  \n",
        "print ('-'*30)\n",
        "total_iters = 0\n",
        "for epoch in range(64):\n",
        "    if epoch == 32:\n",
        "       optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']/10\n",
        "    \n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    model.train() \n",
        "       \n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=ImbalanceSampler(train_labels.flatten().astype(int), BATCH_SIZE, pos_num=posNum), num_workers=2, pin_memory=True, drop_last=True) \n",
        "\n",
        "    for idx, (index, data, targets) in enumerate(trainloader):\n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        predScore = torch.sigmoid(y_pred)\n",
        "\n",
        "        loss = Loss(predScore, targets, index_s=index)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_pred.append(predScore.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "\n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    train_auc = roc_auc_score(train_true, train_pred) \n",
        "    train_prc = average_precision_score(train_true, train_pred)\n",
        "\n",
        "    model.eval()\n",
        "    test_pred = []\n",
        "    test_true = [] \n",
        "    for j, data in enumerate(testloader):\n",
        "        _, test_data, test_targets = data\n",
        "        test_data = test_data.cuda()\n",
        "        y_pred = model(test_data)\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "        test_pred.append(y_pred.cpu().detach().numpy())\n",
        "        test_true.append(test_targets.numpy())\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "     \n",
        "    val_auc =  roc_auc_score(test_true, test_pred) \n",
        "    val_prc = average_precision_score(test_true, test_pred)\n",
        "    model.train()\n",
        "    print(\"epoch: {}, train_loss: {:4f}, train_ap:{:4f}, test_ap:{:4f},  lr:{:4f}\".format(epoch, loss.item(), train_prc, val_prc,  optimizer.param_groups[0]['lr'] ))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "epoch: 0, train_loss: 0.003676, train_ap:0.019629, test_ap:0.554844,  lr:0.600000\n",
            "epoch: 1, train_loss: 0.003618, train_ap:0.022199, test_ap:0.586944,  lr:0.600000\n",
            "epoch: 2, train_loss: 0.003648, train_ap:0.023676, test_ap:0.573761,  lr:0.600000\n",
            "epoch: 3, train_loss: 0.003301, train_ap:0.023032, test_ap:0.595342,  lr:0.600000\n",
            "epoch: 4, train_loss: 0.003373, train_ap:0.027908, test_ap:0.578586,  lr:0.600000\n",
            "epoch: 5, train_loss: 0.003489, train_ap:0.028269, test_ap:0.606583,  lr:0.600000\n",
            "epoch: 6, train_loss: 0.004958, train_ap:0.031157, test_ap:0.623569,  lr:0.600000\n",
            "epoch: 7, train_loss: 0.008316, train_ap:0.037150, test_ap:0.627279,  lr:0.600000\n",
            "epoch: 8, train_loss: 0.005164, train_ap:0.033198, test_ap:0.638722,  lr:0.600000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}