{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[LibAUC]Training_AUPRCLoss_on_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwnB4qhzRo-U"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw6cuynswP_w"
      },
      "source": [
        "!pip install libauc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qWCXSTRvIK"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvcM8kpziqv4"
      },
      "source": [
        "from libauc.losses import SOAPLoss\n",
        "from libauc.optimizers import SGD\n",
        "from libauc.models import ResNet18\n",
        "from libauc.datasets import CIFAR10\n",
        "from libauc.datasets import ImbalanceGenerator, ImbalanceSampler \n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N286JDgSIy4"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GXbHx1SLfy"
      },
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE-hFHH1SNuu"
      },
      "source": [
        "# **Image Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg85RS7_woYS"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                                \n",
        "                              transforms.RandomCrop(image_size, padding=4),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                              \n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                              ])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return idx, image, target\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEVuk9mWSWgE"
      },
      "source": [
        "# **Paramaters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Wn9WTGSdmD"
      },
      "source": [
        "# paramaters\n",
        "imratio = 0.02\n",
        "SEED = 123\n",
        "BATCH_SIZE = 64\n",
        "lr =  0.6\n",
        "weight_decay = 2e-4\n",
        "margin = 0.5\n",
        "gamma = 0.99\n",
        "posNum = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5TQ6QMSZ_Z"
      },
      "source": [
        "# **Loading datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsp3lUzXShgI",
        "outputId": "45549b93-9840-4185-f553-aa2595ff48d4"
      },
      "source": [
        "# dataloader \n",
        "(train_data, train_label), (test_data, test_label) = CIFAR10()\n",
        "(train_images, train_labels) = ImbalanceGenerator(train_data, train_label, imratio=imratio, shuffle=True, random_seed=SEED)\n",
        "(test_images, test_labels) = ImbalanceGenerator(test_data, test_label, is_balanced=True,  random_seed=SEED)\n",
        "\n",
        "train_dataset = ImageDataset(train_images, train_labels)\n",
        "test_dataset = ImageDataset(test_images, test_labels, mode='test')\n",
        "testloader = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE, shuffle=False, num_workers=1,  pin_memory=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_SAMPLES: [25510], POS:NEG: [510 : 25000], POS_RATIO: 0.0200\n",
            "NUM_SAMPLES: [10000], POS:NEG: [5000 : 5000], POS_RATIO: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyXxZxRvSjOO"
      },
      "source": [
        "# **Creating models & AUC Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC4ihPQASmSY",
        "outputId": "2ef8ca9e-37bf-4210-f82c-0127c0dcb70a"
      },
      "source": [
        "set_all_seeds(456)\n",
        "model = ResNet18(pretrained=False, last_activation=None)  # last_activation=False: don't include sigmoid function in the last layer\n",
        "model = model.cuda()\n",
        "\n",
        "Loss = SOAPLoss(margin=margin, gamma=gamma, data_len=train_labels.shape[0])\n",
        "optimizer = SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.modules.activation.ReLU'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0nJp7NS4Ne"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64xZXszhwqmK",
        "outputId": "cb961669-c6cc-4e24-e744-8590ecd17fc1"
      },
      "source": [
        "# training \n",
        "model.train()\n",
        "losses = []  \n",
        "print ('-'*30)\n",
        "total_iters = 0\n",
        "for epoch in range(64):\n",
        "    if epoch == 32:\n",
        "       optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']/10\n",
        "    \n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    model.train() \n",
        "       \n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=ImbalanceSampler(train_labels.flatten().astype(int), BATCH_SIZE, pos_num=posNum), num_workers=2, pin_memory=True, drop_last=True) \n",
        "\n",
        "    for idx, (index, data, targets) in enumerate(trainloader):\n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        y_prob = torch.sigmoid(y_pred)\n",
        "        loss = Loss(y_prob, targets, index_s=index)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_pred.append(y_prob.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "\n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    train_auc = roc_auc_score(train_true, train_pred) \n",
        "    train_prc = average_precision_score(train_true, train_pred)\n",
        "\n",
        "    model.eval()\n",
        "    test_pred = []\n",
        "    test_true = [] \n",
        "    for j, data in enumerate(testloader):\n",
        "        _, test_data, test_targets = data\n",
        "        test_data = test_data.cuda()\n",
        "        y_pred = model(test_data)\n",
        "        y_prob = torch.sigmoid(y_pred)\n",
        "        test_pred.append(y_prob.cpu().detach().numpy())\n",
        "        test_true.append(test_targets.numpy())\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "     \n",
        "    val_auc =  roc_auc_score(test_true, test_pred) \n",
        "    val_prc = average_precision_score(test_true, test_pred)\n",
        "    \n",
        "    model.train()\n",
        "    print(\"epoch: {}, train_loss: {:4f}, train_ap:{:4f}, test_ap:{:4f},  lr:{:4f}\".format(epoch, loss.item(), train_prc, val_prc,  optimizer.param_groups[0]['lr'] ))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "epoch: 0, train_loss: 0.004258, train_ap:0.018660, test_ap:0.589064,  lr:0.600000\n",
            "epoch: 1, train_loss: 0.004281, train_ap:0.022859, test_ap:0.566373,  lr:0.600000\n",
            "epoch: 2, train_loss: 0.004342, train_ap:0.023260, test_ap:0.605101,  lr:0.600000\n",
            "epoch: 3, train_loss: 0.004283, train_ap:0.025631, test_ap:0.632595,  lr:0.600000\n",
            "epoch: 4, train_loss: 0.003922, train_ap:0.026512, test_ap:0.597072,  lr:0.600000\n",
            "epoch: 5, train_loss: 0.004080, train_ap:0.027945, test_ap:0.617341,  lr:0.600000\n",
            "epoch: 6, train_loss: 0.003196, train_ap:0.026796, test_ap:0.657292,  lr:0.600000\n",
            "epoch: 7, train_loss: 0.005543, train_ap:0.030167, test_ap:0.608830,  lr:0.600000\n",
            "epoch: 8, train_loss: 0.003187, train_ap:0.030196, test_ap:0.623877,  lr:0.600000\n",
            "epoch: 9, train_loss: 0.004682, train_ap:0.029599, test_ap:0.680011,  lr:0.600000\n",
            "epoch: 10, train_loss: 0.005683, train_ap:0.034481, test_ap:0.677321,  lr:0.600000\n",
            "epoch: 11, train_loss: 0.004945, train_ap:0.038585, test_ap:0.670743,  lr:0.600000\n",
            "epoch: 12, train_loss: 0.001891, train_ap:0.040166, test_ap:0.657048,  lr:0.600000\n",
            "epoch: 13, train_loss: 0.003580, train_ap:0.041690, test_ap:0.691756,  lr:0.600000\n",
            "epoch: 14, train_loss: 0.002805, train_ap:0.043009, test_ap:0.687583,  lr:0.600000\n",
            "epoch: 15, train_loss: 0.002286, train_ap:0.045007, test_ap:0.685762,  lr:0.600000\n",
            "epoch: 16, train_loss: 0.004156, train_ap:0.050849, test_ap:0.688006,  lr:0.600000\n",
            "epoch: 17, train_loss: 0.005155, train_ap:0.050898, test_ap:0.677895,  lr:0.600000\n",
            "epoch: 18, train_loss: 0.004530, train_ap:0.050579, test_ap:0.712861,  lr:0.600000\n",
            "epoch: 19, train_loss: 0.002797, train_ap:0.053339, test_ap:0.683172,  lr:0.600000\n",
            "epoch: 20, train_loss: 0.002133, train_ap:0.053934, test_ap:0.695314,  lr:0.600000\n",
            "epoch: 21, train_loss: 0.006211, train_ap:0.068224, test_ap:0.662126,  lr:0.600000\n",
            "epoch: 22, train_loss: 0.001919, train_ap:0.057214, test_ap:0.721190,  lr:0.600000\n",
            "epoch: 23, train_loss: 0.003380, train_ap:0.061006, test_ap:0.712388,  lr:0.600000\n",
            "epoch: 24, train_loss: 0.006127, train_ap:0.069840, test_ap:0.698397,  lr:0.600000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}