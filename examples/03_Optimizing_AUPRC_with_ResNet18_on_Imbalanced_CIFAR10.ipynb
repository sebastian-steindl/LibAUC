{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_Optimizing_AUPRC_with_ResNet18_on_Imbalanced_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPfAfYgpobNo"
      },
      "source": [
        "*   Author: Zhuoning Yuan, Qi Qi\n",
        "*   Project: https://github.com/yzhuoning/LibAUC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwnB4qhzRo-U"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw6cuynswP_w",
        "outputId": "02d353e8-878f-42a3-b2cb-4b3dbf2d9d8f"
      },
      "source": [
        "!pip install --upgrade libauc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting libauc\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/2e/c3e6cae387f51ff6a7288dc4ea4282b7210139c22ce8388ea03f73f8d979/libauc-1.1.1-py3-none-any.whl (40kB)\n",
            "\r\u001b[K     |████████▏                       | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20kB 12.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.6MB/s \n",
            "\u001b[?25hInstalling collected packages: libauc\n",
            "Successfully installed libauc-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qWCXSTRvIK"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvcM8kpziqv4"
      },
      "source": [
        "from libauc.losses import APLoss_SH\n",
        "from libauc.optimizers import SOAP_SGD\n",
        "from libauc.models import ResNet18\n",
        "from libauc.datasets import CIFAR10\n",
        "from libauc.datasets import ImbalanceGenerator, ImbalanceSampler \n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N286JDgSIy4"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GXbHx1SLfy"
      },
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE-hFHH1SNuu"
      },
      "source": [
        "# **Image Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg85RS7_woYS"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                                \n",
        "                              transforms.RandomCrop(image_size, padding=4),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                              \n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                              ])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return idx, image, target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEVuk9mWSWgE"
      },
      "source": [
        "# **Paramaters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Wn9WTGSdmD"
      },
      "source": [
        "# paramaters\n",
        "imratio = 0.02\n",
        "SEED = 123\n",
        "BATCH_SIZE = 64\n",
        "lr =  0.6\n",
        "weight_decay = 2e-4\n",
        "margin = 0.5\n",
        "beta = 0.99 # this refers to gamma in the paper\n",
        "posNum = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5TQ6QMSZ_Z"
      },
      "source": [
        "# **Loading datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsp3lUzXShgI",
        "outputId": "aa04fb08-a506-4ecc-a578-2fc29c6de12f"
      },
      "source": [
        "# dataloader \n",
        "(train_data, train_label), (test_data, test_label) = CIFAR10()\n",
        "(train_images, train_labels) = ImbalanceGenerator(train_data, train_label, imratio=imratio, shuffle=True, random_seed=SEED)\n",
        "(test_images, test_labels) = ImbalanceGenerator(test_data, test_label, is_balanced=True,  random_seed=SEED)\n",
        "\n",
        "train_dataset = ImageDataset(train_images, train_labels)\n",
        "test_dataset = ImageDataset(test_images, test_labels, mode='test')\n",
        "testloader = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE, shuffle=False, num_workers=1,  pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 12s 0us/step\n",
            "NUM_SAMPLES: [25510], POS:NEG: [510 : 25000], POS_RATIO: 0.0200\n",
            "NUM_SAMPLES: [10000], POS:NEG: [5000 : 5000], POS_RATIO: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyXxZxRvSjOO"
      },
      "source": [
        "# **Creating models & AUC Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC4ihPQASmSY"
      },
      "source": [
        "set_all_seeds(456)\n",
        "model = ResNet18(pretrained=False, last_activation=None) \n",
        "model = model.cuda()\n",
        "\n",
        "# APLoss_SH requires ImbalanceSampler() with pos_num>=1!\n",
        "Loss = APLoss_SH(margin=margin, beta=beta, data_len=train_labels.shape[0])\n",
        "optimizer = SOAP_SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0nJp7NS4Ne"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64xZXszhwqmK",
        "outputId": "29dbd603-699d-499e-bf8c-bff4e111e7f1"
      },
      "source": [
        "# training \n",
        "model.train()\n",
        "losses = []  \n",
        "print ('-'*30)\n",
        "total_iters = 0\n",
        "for epoch in range(64):\n",
        "    if epoch == 32:\n",
        "       optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']/10\n",
        "    \n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    model.train() \n",
        "       \n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=ImbalanceSampler(train_labels.flatten().astype(int), BATCH_SIZE, pos_num=posNum), num_workers=2, pin_memory=True, drop_last=True) \n",
        "\n",
        "    for idx, (index, data, targets) in enumerate(trainloader):\n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        y_prob = torch.sigmoid(y_pred)\n",
        "        loss = Loss(y_prob, targets, index_s=index)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_pred.append(y_prob.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "\n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    train_auc = roc_auc_score(train_true, train_pred) \n",
        "    train_prc = average_precision_score(train_true, train_pred)\n",
        "\n",
        "    model.eval()\n",
        "    test_pred = []\n",
        "    test_true = [] \n",
        "    for j, data in enumerate(testloader):\n",
        "        _, test_data, test_targets = data\n",
        "        test_data = test_data.cuda()\n",
        "        y_pred = model(test_data)\n",
        "        y_prob = torch.sigmoid(y_pred)\n",
        "        test_pred.append(y_prob.cpu().detach().numpy())\n",
        "        test_true.append(test_targets.numpy())\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "     \n",
        "    val_auc =  roc_auc_score(test_true, test_pred) \n",
        "    val_prc = average_precision_score(test_true, test_pred)\n",
        "    \n",
        "    model.train()\n",
        "    print(\"epoch: {}, train_loss: {:4f}, train_ap:{:4f}, test_ap:{:4f},  lr:{:4f}\".format(epoch, loss.item(), train_prc, val_prc,  optimizer.param_groups[0]['lr'] ))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "epoch: 0, train_loss: 0.004271, train_ap:0.016977, test_ap:0.574469,  lr:0.600000\n",
            "epoch: 1, train_loss: 0.003858, train_ap:0.024827, test_ap:0.611937,  lr:0.600000\n",
            "epoch: 2, train_loss: 0.003060, train_ap:0.025190, test_ap:0.613633,  lr:0.600000\n",
            "epoch: 3, train_loss: 0.001054, train_ap:0.025885, test_ap:0.589008,  lr:0.600000\n",
            "epoch: 4, train_loss: 0.003762, train_ap:0.025945, test_ap:0.610585,  lr:0.600000\n",
            "epoch: 5, train_loss: 0.004220, train_ap:0.025707, test_ap:0.621060,  lr:0.600000\n",
            "epoch: 6, train_loss: 0.004753, train_ap:0.029162, test_ap:0.650009,  lr:0.600000\n",
            "epoch: 7, train_loss: 0.002049, train_ap:0.028029, test_ap:0.651799,  lr:0.600000\n",
            "epoch: 8, train_loss: 0.005533, train_ap:0.031953, test_ap:0.634691,  lr:0.600000\n",
            "epoch: 9, train_loss: 0.006606, train_ap:0.031283, test_ap:0.664364,  lr:0.600000\n",
            "epoch: 10, train_loss: 0.003242, train_ap:0.035829, test_ap:0.663829,  lr:0.600000\n",
            "epoch: 11, train_loss: 0.003200, train_ap:0.034632, test_ap:0.667932,  lr:0.600000\n",
            "epoch: 12, train_loss: 0.003973, train_ap:0.040508, test_ap:0.665011,  lr:0.600000\n",
            "epoch: 13, train_loss: 0.005694, train_ap:0.040642, test_ap:0.656661,  lr:0.600000\n",
            "epoch: 14, train_loss: 0.004698, train_ap:0.045937, test_ap:0.690562,  lr:0.600000\n",
            "epoch: 15, train_loss: 0.002330, train_ap:0.041138, test_ap:0.690237,  lr:0.600000\n",
            "epoch: 16, train_loss: 0.003501, train_ap:0.049018, test_ap:0.701057,  lr:0.600000\n",
            "epoch: 17, train_loss: 0.006083, train_ap:0.046031, test_ap:0.681123,  lr:0.600000\n",
            "epoch: 18, train_loss: 0.003363, train_ap:0.046177, test_ap:0.712818,  lr:0.600000\n",
            "epoch: 19, train_loss: 0.004291, train_ap:0.058447, test_ap:0.700808,  lr:0.600000\n",
            "epoch: 20, train_loss: 0.002937, train_ap:0.053940, test_ap:0.726648,  lr:0.600000\n",
            "epoch: 21, train_loss: 0.002181, train_ap:0.052920, test_ap:0.701404,  lr:0.600000\n",
            "epoch: 22, train_loss: 0.004160, train_ap:0.065489, test_ap:0.709725,  lr:0.600000\n",
            "epoch: 23, train_loss: 0.000902, train_ap:0.064906, test_ap:0.733955,  lr:0.600000\n",
            "epoch: 24, train_loss: 0.004238, train_ap:0.056451, test_ap:0.713158,  lr:0.600000\n",
            "epoch: 25, train_loss: 0.003342, train_ap:0.061654, test_ap:0.704481,  lr:0.600000\n",
            "epoch: 26, train_loss: 0.004387, train_ap:0.073824, test_ap:0.656795,  lr:0.600000\n",
            "epoch: 27, train_loss: 0.002489, train_ap:0.057101, test_ap:0.682574,  lr:0.600000\n",
            "epoch: 28, train_loss: 0.003942, train_ap:0.070090, test_ap:0.698008,  lr:0.600000\n",
            "epoch: 29, train_loss: 0.005608, train_ap:0.072451, test_ap:0.715312,  lr:0.600000\n",
            "epoch: 30, train_loss: 0.002267, train_ap:0.076632, test_ap:0.701396,  lr:0.600000\n",
            "epoch: 31, train_loss: 0.002473, train_ap:0.068592, test_ap:0.682636,  lr:0.600000\n",
            "epoch: 32, train_loss: 0.001541, train_ap:0.112784, test_ap:0.768328,  lr:0.060000\n",
            "epoch: 33, train_loss: 0.001644, train_ap:0.144813, test_ap:0.767963,  lr:0.060000\n",
            "epoch: 34, train_loss: 0.006375, train_ap:0.157088, test_ap:0.768452,  lr:0.060000\n",
            "epoch: 35, train_loss: 0.001094, train_ap:0.179965, test_ap:0.773722,  lr:0.060000\n",
            "epoch: 36, train_loss: 0.004133, train_ap:0.202447, test_ap:0.772339,  lr:0.060000\n",
            "epoch: 37, train_loss: 0.001792, train_ap:0.254825, test_ap:0.770118,  lr:0.060000\n",
            "epoch: 38, train_loss: 0.000963, train_ap:0.234556, test_ap:0.767783,  lr:0.060000\n",
            "epoch: 39, train_loss: 0.003570, train_ap:0.258397, test_ap:0.774377,  lr:0.060000\n",
            "epoch: 40, train_loss: 0.004182, train_ap:0.269499, test_ap:0.778586,  lr:0.060000\n",
            "epoch: 41, train_loss: 0.001383, train_ap:0.280708, test_ap:0.780779,  lr:0.060000\n",
            "epoch: 42, train_loss: 0.003179, train_ap:0.299375, test_ap:0.768955,  lr:0.060000\n",
            "epoch: 43, train_loss: 0.000490, train_ap:0.296350, test_ap:0.773780,  lr:0.060000\n",
            "epoch: 44, train_loss: 0.003341, train_ap:0.322787, test_ap:0.784294,  lr:0.060000\n",
            "epoch: 45, train_loss: 0.005879, train_ap:0.323731, test_ap:0.774858,  lr:0.060000\n",
            "epoch: 46, train_loss: 0.002719, train_ap:0.335308, test_ap:0.762177,  lr:0.060000\n",
            "epoch: 47, train_loss: 0.005522, train_ap:0.357756, test_ap:0.770622,  lr:0.060000\n",
            "epoch: 48, train_loss: 0.000227, train_ap:0.349642, test_ap:0.780673,  lr:0.060000\n",
            "epoch: 49, train_loss: 0.001870, train_ap:0.389387, test_ap:0.773560,  lr:0.060000\n",
            "epoch: 50, train_loss: 0.002641, train_ap:0.389520, test_ap:0.769012,  lr:0.060000\n",
            "epoch: 51, train_loss: 0.001884, train_ap:0.388094, test_ap:0.770558,  lr:0.060000\n",
            "epoch: 52, train_loss: 0.002183, train_ap:0.421522, test_ap:0.767560,  lr:0.060000\n",
            "epoch: 53, train_loss: 0.000760, train_ap:0.419690, test_ap:0.773272,  lr:0.060000\n",
            "epoch: 54, train_loss: 0.003674, train_ap:0.455906, test_ap:0.774409,  lr:0.060000\n",
            "epoch: 55, train_loss: 0.003387, train_ap:0.475861, test_ap:0.784708,  lr:0.060000\n",
            "epoch: 56, train_loss: 0.001232, train_ap:0.415505, test_ap:0.771910,  lr:0.060000\n",
            "epoch: 57, train_loss: 0.003686, train_ap:0.475177, test_ap:0.764705,  lr:0.060000\n",
            "epoch: 58, train_loss: 0.000178, train_ap:0.489697, test_ap:0.750644,  lr:0.060000\n",
            "epoch: 59, train_loss: 0.000057, train_ap:0.459997, test_ap:0.773862,  lr:0.060000\n",
            "epoch: 60, train_loss: 0.000199, train_ap:0.478920, test_ap:0.768924,  lr:0.060000\n",
            "epoch: 61, train_loss: 0.006328, train_ap:0.532187, test_ap:0.752478,  lr:0.060000\n",
            "epoch: 62, train_loss: 0.000094, train_ap:0.495682, test_ap:0.745208,  lr:0.060000\n",
            "epoch: 63, train_loss: 0.001350, train_ap:0.519776, test_ap:0.770302,  lr:0.060000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
