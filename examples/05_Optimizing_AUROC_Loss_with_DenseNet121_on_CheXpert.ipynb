{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "05.Optimizing_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qkb6bYy3rOx"
      },
      "source": [
        "\n",
        "\n",
        "* Author: Zhuoning Yuan\n",
        "* Project: https://github.com/yzhuoning/LibAUC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTJ3ca0u4YQ4"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8iVw1kU3guh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168e09e3-e6d6-4eec-f20b-29e8c48ea1b2"
      },
      "source": [
        "!pip install libauc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./libauc-1.1.3.tar.gz\n",
            "Building wheels for collected packages: libauc\n",
            "  Building wheel for libauc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libauc: filename=libauc-1.1.3-py3-none-any.whl size=46616 sha256=7dc5ff3862c047c52d8780bddf86dba8831bd36f8e9e49b983229d1278beb293\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/e8/72/847ed4dbe693e0bca165e2b9124064bd339f927e6864e40f43\n",
            "Successfully built libauc\n",
            "Installing collected packages: libauc\n",
            "Successfully installed libauc-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlD-4SrE4dVW"
      },
      "source": [
        "# **Downloading CheXpert**\n",
        " \n",
        "*   To request dataset access, you need to apply from CheXpert website: https://stanfordmlgroup.github.io/competitions/chexpert/\n",
        "*   In this tutorial, we use the smaller version of dataset with lower image resolution, i.e., *CheXpert-v1.0-small.zip*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcsJ4eoj3VST"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/chexpert-dataset/CheXpert-v1.0-small.zip /content/\n",
        "!mkdir CheXpert\n",
        "!unzip CheXpert-v1.0-small.zip -d /content/CheXpert/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVvrt3ku4qpq"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGHWer3v4qJo"
      },
      "source": [
        "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.models import DenseNet121, DenseNet169\n",
        "from libauc.datasets import CheXpert\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2swK5Mo7Kca"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiiT5oEp7J3C"
      },
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Bge6KM7lBP"
      },
      "source": [
        "# **Pretraining**\n",
        "* Multi-label classification (5 tasks)   \n",
        "* Adam + CrossEntropy Loss \n",
        "* This step is optional\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkKcegEh72VP",
        "outputId": "6b9494b5-e2e6-432d-b1ee-55d50cc20222"
      },
      "source": [
        "# dataloader\n",
        "root = './CheXpert/CheXpert-v1.0-small/'\n",
        "# Index: -1 denotes multi-label mode including 5 diseases\n",
        "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
        "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)\n",
        "\n",
        "# paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 32\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "\n",
        "# model\n",
        "set_all_seeds(SEED)\n",
        "model = DenseNet121(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
        "model = model.cuda()\n",
        "\n",
        "# define loss & optimizer\n",
        "CELoss = CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# training\n",
        "best_val_auc = 0 \n",
        "for epoch in range(1):\n",
        "    for idx, data in enumerate(trainloader):\n",
        "      train_data, train_labels = data\n",
        "      train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
        "      y_pred = model(train_data)\n",
        "      loss = CELoss(y_pred, train_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        \n",
        "      # validation  \n",
        "      if idx % 400 == 0:\n",
        "         model.eval()\n",
        "         with torch.no_grad():    \n",
        "              test_pred = []\n",
        "              test_true = [] \n",
        "              for jdx, data in enumerate(testloader):\n",
        "                  test_data, test_labels = data\n",
        "                  test_data = test_data.cuda()\n",
        "                  y_pred = model(test_data)\n",
        "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                  test_true.append(test_labels.numpy())\n",
        "            \n",
        "              test_true = np.concatenate(test_true)\n",
        "              test_pred = np.concatenate(test_pred)\n",
        "              val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
        "              model.train()\n",
        "\n",
        "              if best_val_auc < val_auc_mean:\n",
        "                 best_val_auc = val_auc_mean\n",
        "                 torch.save(model.state_dict(), 'ce_pretrained_model.pth')\n",
        "\n",
        "              print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc ))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 191027 images in total, 23385 positive images, 167642 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1224\n",
            "\n",
            "Found 191027 images in total, 61493 positive images, 129534 negative images\n",
            "Edema(C1): imbalance ratio is 0.3219\n",
            "\n",
            "Found 191027 images in total, 12983 positive images, 178044 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0680\n",
            "\n",
            "Found 191027 images in total, 59583 positive images, 131444 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.3119\n",
            "\n",
            "Found 191027 images in total, 76899 positive images, 114128 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.4026\n",
            "\n",
            "------------------------------\n",
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 202 images in total, 66 positive images, 136 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.3267\n",
            "\n",
            "Found 202 images in total, 42 positive images, 160 negative images\n",
            "Edema(C1): imbalance ratio is 0.2079\n",
            "\n",
            "Found 202 images in total, 32 positive images, 170 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.1584\n",
            "\n",
            "Found 202 images in total, 75 positive images, 127 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.3713\n",
            "\n",
            "Found 202 images in total, 64 positive images, 138 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.3168\n",
            "\n",
            "------------------------------\n",
            "Epoch=0, BatchID=0, Val_AUC=0.5061, best_val_auc=0.5061\n",
            "Epoch=0, BatchID=400, Val_AUC=0.8519, best_val_auc=0.8519\n",
            "Epoch=0, BatchID=800, Val_AUC=0.8574, best_val_auc=0.8574\n",
            "Epoch=0, BatchID=1200, Val_AUC=0.8748, best_val_auc=0.8748\n",
            "Epoch=0, BatchID=1600, Val_AUC=0.8787, best_val_auc=0.8787\n",
            "Epoch=0, BatchID=2000, Val_AUC=0.8791, best_val_auc=0.8791\n",
            "Epoch=0, BatchID=2400, Val_AUC=0.8854, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=2800, Val_AUC=0.8830, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=3200, Val_AUC=0.8811, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=3600, Val_AUC=0.8814, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=4000, Val_AUC=0.8761, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=4400, Val_AUC=0.8636, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=4800, Val_AUC=0.8798, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=5200, Val_AUC=0.8706, best_val_auc=0.8854\n",
            "Epoch=0, BatchID=5600, Val_AUC=0.8643, best_val_auc=0.8854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP4adNO97YBV"
      },
      "source": [
        "# **Optimizing AUCM Loss**\n",
        "\n",
        "\n",
        "*   Binary Classification\n",
        "*   PESG + AUCM Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiOrKatkSCNJ",
        "outputId": "3ae196ec-cd12-4471-9860-782a1dfba722"
      },
      "source": [
        "# parameters\n",
        "class_id = 1 # 0:Cardiomegaly, 1:Edema, 2:Consolidation, 3:Atelectasis, 4:Pleural Effusion \n",
        "root = './CheXpert/CheXpert-v1.0-small/'\n",
        "\n",
        "# You can set use_upsampling=True and pass the class name by upsampling_cols=['Cardiomegaly'] to do upsampling. This may improve the performance\n",
        "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=True, use_frontal=True, image_size=224, mode='train', class_index=class_id)\n",
        "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=class_id)\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)\n",
        "\n",
        "# paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 32\n",
        "imratio = traindSet.imratio\n",
        "lr = 0.05 # using smaller learning rate is better\n",
        "gamma = 500\n",
        "weight_decay = 1e-5\n",
        "margin = 1.0\n",
        "\n",
        "# model\n",
        "set_all_seeds(SEED)\n",
        "model = DenseNet121(pretrained=False, last_activation='sigmoid', activations='relu', num_classes=1)\n",
        "model = model.cuda()\n",
        "\n",
        "\n",
        "# load pretrained model\n",
        "if True:\n",
        "  PATH = 'ce_pretrained_model.pth' \n",
        "  state_dict = torch.load(PATH)\n",
        "  state_dict.pop('classifier.weight', None)\n",
        "  state_dict.pop('classifier.bias', None) \n",
        "  model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "\n",
        "# define loss & optimizer\n",
        "Loss = AUCMLoss(imratio=imratio)\n",
        "optimizer = PESG(model, \n",
        "                 a=Loss.a, \n",
        "                 b=Loss.b, \n",
        "                 alpha=Loss.alpha, \n",
        "                 imratio=imratio, \n",
        "                 lr=lr, \n",
        "                 gamma=gamma, \n",
        "                 margin=margin, \n",
        "                 weight_decay=weight_decay)\n",
        "\n",
        "best_val_auc = 0\n",
        "for epoch in range(2):\n",
        "  if epoch > 0:\n",
        "     optimizer.update_regularizer(decay_factor=10)\n",
        "  for idx, data in enumerate(trainloader):\n",
        "      train_data, train_labels = data\n",
        "      train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
        "      y_pred = model(train_data)\n",
        "      loss = Loss(y_pred, train_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # validation\n",
        "      if idx % 400 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():    \n",
        "              test_pred = []\n",
        "              test_true = [] \n",
        "              for jdx, data in enumerate(testloader):\n",
        "                  test_data, test_label = data\n",
        "                  test_data = test_data.cuda()\n",
        "                  y_pred = model(test_data)\n",
        "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                  test_true.append(test_label.numpy())\n",
        "              \n",
        "              test_true = np.concatenate(test_true)\n",
        "              test_pred = np.concatenate(test_pred)\n",
        "              val_auc =  roc_auc_score(test_true, test_pred) \n",
        "              model.train()\n",
        "\n",
        "              if best_val_auc < val_auc:\n",
        "                 best_val_auc = val_auc\n",
        "              \n",
        "        print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, lr=%.4f'%(epoch, idx, val_auc,  optimizer.lr))\n",
        "\n",
        "print ('Best Val_AUC is %.4f'%best_val_auc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upsampling Cardiomegaly...\n",
            "Upsampling Consolidation...\n",
            "------------------------------\n",
            "Found 227395 images in total, 77866 positive images, 149529 negative images\n",
            "Edema(C1): imbalance ratio is 0.3424\n",
            "------------------------------\n",
            "------------------------------\n",
            "Found 202 images in total, 42 positive images, 160 negative images\n",
            "Edema(C1): imbalance ratio is 0.2079\n",
            "------------------------------\n",
            "Epoch=0, BatchID=0, Val_AUC=0.6281, lr=0.0500\n",
            "Epoch=0, BatchID=400, Val_AUC=0.9185, lr=0.0500\n",
            "Epoch=0, BatchID=800, Val_AUC=0.8872, lr=0.0500\n",
            "Epoch=0, BatchID=1200, Val_AUC=0.9226, lr=0.0500\n",
            "Epoch=0, BatchID=1600, Val_AUC=0.9058, lr=0.0500\n",
            "Epoch=0, BatchID=2000, Val_AUC=0.9016, lr=0.0500\n",
            "Epoch=0, BatchID=2400, Val_AUC=0.9028, lr=0.0500\n",
            "Epoch=0, BatchID=2800, Val_AUC=0.9009, lr=0.0500\n",
            "Epoch=0, BatchID=3200, Val_AUC=0.9131, lr=0.0500\n",
            "Epoch=0, BatchID=3600, Val_AUC=0.9155, lr=0.0500\n",
            "Epoch=0, BatchID=4000, Val_AUC=0.8888, lr=0.0500\n",
            "Epoch=0, BatchID=4400, Val_AUC=0.9263, lr=0.0500\n",
            "Epoch=0, BatchID=4800, Val_AUC=0.8929, lr=0.0500\n",
            "Epoch=0, BatchID=5200, Val_AUC=0.9162, lr=0.0500\n",
            "Epoch=0, BatchID=5600, Val_AUC=0.9027, lr=0.0500\n",
            "Epoch=0, BatchID=6000, Val_AUC=0.8917, lr=0.0500\n",
            "Epoch=0, BatchID=6400, Val_AUC=0.9211, lr=0.0500\n",
            "Epoch=0, BatchID=6800, Val_AUC=0.8257, lr=0.0500\n",
            "Reducing learning rate to 0.00500 @ T=7107!\n",
            "Updating regularizer @ T=7107!\n",
            "Epoch=1, BatchID=0, Val_AUC=0.8799, lr=0.0050\n",
            "Epoch=1, BatchID=400, Val_AUC=0.9315, lr=0.0050\n",
            "Epoch=1, BatchID=800, Val_AUC=0.9385, lr=0.0050\n",
            "Epoch=1, BatchID=1200, Val_AUC=0.9324, lr=0.0050\n",
            "Epoch=1, BatchID=1600, Val_AUC=0.9292, lr=0.0050\n",
            "Epoch=1, BatchID=2000, Val_AUC=0.9378, lr=0.0050\n",
            "Epoch=1, BatchID=2400, Val_AUC=0.9329, lr=0.0050\n",
            "Epoch=1, BatchID=2800, Val_AUC=0.9372, lr=0.0050\n",
            "Epoch=1, BatchID=3200, Val_AUC=0.9376, lr=0.0050\n",
            "Epoch=1, BatchID=3600, Val_AUC=0.9385, lr=0.0050\n",
            "Epoch=1, BatchID=4000, Val_AUC=0.9344, lr=0.0050\n",
            "Epoch=1, BatchID=4400, Val_AUC=0.9324, lr=0.0050\n",
            "Epoch=1, BatchID=4800, Val_AUC=0.9396, lr=0.0050\n",
            "Epoch=1, BatchID=5200, Val_AUC=0.9414, lr=0.0050\n",
            "Epoch=1, BatchID=5600, Val_AUC=0.9394, lr=0.0050\n",
            "Epoch=1, BatchID=6000, Val_AUC=0.9366, lr=0.0050\n",
            "Epoch=1, BatchID=6400, Val_AUC=0.9420, lr=0.0050\n",
            "Epoch=1, BatchID=6800, Val_AUC=0.9372, lr=0.0050\n",
            "Best Val AUC is 0.9420\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}